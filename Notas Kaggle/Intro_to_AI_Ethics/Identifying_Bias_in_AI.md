# Identifying Bias in AI

- Bias: se refiere a las consecuencias negativas y no deseadas de las aplicaciones de ML, especialmente si las consecuencias afectan desproporcionadamente a ciertos grupos.

- Historical Bias: Ocurre cuando el estado del mundo cuando los datos fueron generados es defectuoso.

- Repressentation Bias: Ocurre cuando se construyen los datasets para entrenar el modelo, no representan de manera correcta a las personas a las cuales les va a servir.

- Measurment Bias: Ocurre cuando la precisión del modelo varia dependiendo los grupos.

- Aggregation Bias: Ocurre cuando los grupos son combinados inapropiadamente esto hace que el modelo no se desarrolle bien con ningun grupo o solo funciona bien con la mayoria.

- Evaluation Bias: Ocurre cuando evaluando un modelo si la benchmark data no representa a la población a la que va a servir.

- Deployment Bias: Ocurre cuando el modelo esta entrenado para resolver un problema de una manera pero se le presenta otra situacion que no conoce.